# 소 발정 행동 판별 예측 

pytorch기반의 detectron2를 이용하여 발정/비발정 소를 구분/예측해내는 알고리즘을 만들었다.

http://aifactory.space/competition/detail/1953
위 공모전에 참여하여 소 축사 이미지와 각 소들의 데이터를 받고, 그 데이터를 이용하여 소의 발정기인지 아닌지를 구별해내는 알고리즘이다.

colab의 ipynb파일에 작성


## 소 발정기 판별 with detectron2.ipynb 사용법 및 각 셀에 대한 설명

첫 셀과 두번째 셀은 torch==1.9.0+cu102 torchvision==0.10.0+cu102 버젼을 설치. 위 파일은 cu102버젼을 사용

세번째 셀과 네번째 셀은 데이터가 있는 구글 드라이브를 마운트, 실행 경로 설정

다섯번째 셀은 모델 성능 검증을 위한 valid data를 따로 뺄 폴더 생성

일곱번째 셀은 필요한 라이브러리 임포트

여덟번째 셀은 학습시킬 데이터가 있는 폴더로 경로 이동

아홉번째 셀은 학습할 데이터가 있는 폴더에서 학습에 사용될 이미지 파일들을 추출
val_samples 숫자를 통해 원하는 양의 데이터를 학습시킬 데이터와 겁증시킬 데이터로 나눔

열한번째 셀은 다시 학습시킬 때 검증을 위해 옮겨진 파일들을 다시 원래대로 되돌림

열두번째 셀은 학습시킬 데이터중 이미지에 속한 각 소의 데이터값들이 저장된 json파일을 불러와 읽고 학습에 편리하게 구조 변경

열네번째 셀은 json에서 불러온 소들의 데이터 값을 datasetcatalog와 metadata로 등록

열다섯번째 셀은 json에서 추출한 데이터 값과 이미지를 매치해 잘 작업 되었는지 확인

열일곱번째 셀은 모델 구축 및 학습
COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml 모델을 불러와 이를 바탕으로 학습
학습시킬대 실행이 train폴더 안에서 실행되어야함

스물두번째 셀은 가장 잘 학습된 모델인 model_final.pth파일을 불러오고 thresh값 설정

스물세번째 셀은 학습된 모델을 이용하여 모델이 잘 학습하였는지 확인

스물네번째 셀은 모델의 출력에서 segmentation이 true와 false로만 출력되는것을 좌표로 전환하는 함수 정의

스물아홉번째 셀은 테스트할 이미지의 목록 추출

서른한번째 셀은 테스트할 이미지의 소에 대하여 모델을 통하여 값을 예측 및 coco - json파일 형식으로 저장
