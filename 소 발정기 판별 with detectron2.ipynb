{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"소 발정기 판별 with detectron2.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNggJvPO9wKeErjcjuPWCEw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"zARYnZIWP2-v"},"outputs":[],"source":["!pip install pyyaml==5.1\n","!pip install torch==1.9.0+cu102 torchvision==0.10.0+cu102 -f https://download.pytorch.org/whl/torch_stable.html\n","!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu102/torch1.9/index.html"]},{"cell_type":"code","source":["import torch, torchvision\n","print(torch.__version__, torch.cuda.is_available())"],"metadata":{"id":"HeYU4UOORHP_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"39-uPLDz5mO_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%cd drive/My\\ Drive/dataset\n","!ls\n","!pwd"],"metadata":{"id":"Mip2QZDz6Mld"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!mkdir val_images"],"metadata":{"id":"KjbsjeRu-c2A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!ls"],"metadata":{"id":"AVcwrxTt_-Ce"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import detectron2\n","from detectron2.utils.logger import setup_logger\n","setup_logger()\n","\n","import numpy as np\n","import os, json, cv2, random\n","from google.colab.patches import cv2_imshow\n","\n","from detectron2 import model_zoo\n","from detectron2.engine import DefaultPredictor\n","from detectron2.config import get_cfg\n","from detectron2.utils.visualizer import Visualizer\n","from detectron2.data import MetadataCatalog, DatasetCatalog"],"metadata":{"id":"L_l_wtviR8_A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%cd train_images"],"metadata":{"id":"7z3Q9JrZAkRD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import random\n"," \n","root_dir = '.'\n","\n","img_path_list = []\n","possible_img_extension = ['.jpg', '.PNG'] # 이미지 확장자들\n"," \n","for (root, dirs, files) in os.walk(root_dir):\n","    if len(files) > 0:\n","        for file_name in files:\n","            if os.path.splitext(file_name)[1] in possible_img_extension:\n","                img_path = root + '/' + file_name\n","                \n","                # 경로에서 \\를 모두 /로 바꿔줘야함\n","                img_path = img_path.replace('\\\\', '/') # \\는 \\\\로 나타내야함 \n","                img_path = img_path[2:]        \n","                img_path_list.append(img_path)\n","\n","img_path_list.sort()\n","\n","#print(img_path_list)\n","# img_path_list = os.listdir('.')\n","# print(sorted(img_path_list))\n","\n","# dataset_dicts = get_train_dicts()\n","\n","val_samples = 0\n","# random.Random(1000).shuffle(img_path_list)\n","# random.Random(1000).shuffle(dataset_dicts)\n","val_images = sorted(random.sample(img_path_list, val_samples))\n","\n","# train_input_img_paths = img_path_list[:-val_samples]\n","# train_dicts = dataset_dicts[:-val_samples]\n","# val_input_img_paths = img_path_list[-val_samples:]\n","# val_dicts = dataset_dicts[-val_samples:]\n","\n","start = './'\n","destination = '../val_images/'\n","for image in val_images:\n","  os.replace(start + image, destination + image)\n","print(len(os.listdir(destination)))\n"],"metadata":{"id":"4P06pOKw7jxS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(img_path_list)"],"metadata":{"id":"yt8HaGH0T1cy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 파일 원래대로 돌리기\n","for image in os.listdir(destination):\n","  os.replace(destination + image, start + image)\n","print('destination : {}, start : {}'.format(len(os.listdir(destination)), len(os.listdir(start))))"],"metadata":{"id":"WammGuD19--y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from detectron2.structures import BoxMode\n","\n","def get_train_dicts(dir):\n","  json_file = os.path.join('..', 'train_answer.json')\n","  with open(json_file) as f:\n","    imgs_anns = json.load(f)\n","\n","  dataset_dicts = []\n","  objects = []\n","\n","  for _, v in enumerate(imgs_anns['annotations']):\n","    if objects == []:\n","      v = [v]\n","      objects.append(v)\n","      temp = 0\n","    elif v['image_id'] > objects[temp][0]['image_id']:\n","      v = [v]\n","      objects.append(v)\n","      temp += 1\n","    else:\n","      objects[temp].append(v)\n","\n","  for idx, v in enumerate(imgs_anns['images']):\n","    record = {}\n","\n","    record['file_name'] = v['file_name']\n","    record['image_id'] = v['id']\n","    record['height'] = v['height']\n","    record['width'] = v['width']\n","\n","    annos = objects[idx]\n","    objs = []\n","\n","    for anno in annos:\n","      poly = anno['segmentation']\n","      px = []\n","      py = []\n","      for idx, pos in enumerate(poly):\n","        if idx % 2 == 0:\n","          px.append(pos)\n","        else:\n","          py.append(pos)\n","          \n","      obj = {\n","          'bbox': [np.min(px), np.min(py), np.max(px), np.max(py)],\n","          'bbox_mode': BoxMode.XYXY_ABS,\n","          'segmentation': [poly],\n","          'category_id': anno['category_id']-1,\n","      }\n","\n","      objs.append(obj)\n","\n","    record['annotations'] = objs\n","    dataset_dicts.append(record)\n","\n","  val_images = os.listdir('../val_images')\n","  \n","  data1 = dataset_dicts[:2000]\n","  data2 = dataset_dicts[2000:]\n","\n","  if dir == '../train_images':       \n","    for i in data1:\n","      if i['file_name'] in val_images:\n","        dataset_dicts.remove(i)\n","\n","  elif dir == '../val_images':\n","    for i in data1:\n","      if i['file_name'] not in val_images:\n","        dataset_dicts.remove(i)\n","\n","\n","  if dir == '../train_images':\n","    for i in data2:\n","      if i['file_name'] in val_images:\n","        dataset_dicts.remove(i)\n","\n","  elif dir == '../val_images':\n","    for i in data2:\n","      if i['file_name'] not in val_images:\n","        dataset_dicts.remove(i)\n","\n","  return dataset_dicts"],"metadata":{"id":"2J0zICOm9_sX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(len(os.listdir('../val_images')))\n","print(len(os.listdir('../train_images')))\n","print(len(get_train_dicts('../train_images')))\n","print(len(get_train_dicts('../val_images')))\n"],"metadata":{"id":"4fjrdSpW-CSU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for d in ['train', 'val']:\n","  DatasetCatalog.register(d + '_images', lambda d=d: get_train_dicts('../' + d + '_images'))\n","  MetadataCatalog.get(d + '_images').set(thing_classes=['cow', 'cow1'])\n","\n","\n","# for d in ['train', 'val']:\n","#   if d == 'train':\n","#     # DatasetCatalog.register(d + '_images', lambda d=d: get_train_dicts('../' + d + '_images'))\n","#     print('d')\n","#   else:\n","#     # DatasetCatalog.register(d + '_images', lambda d=d: get_train_dicts('../' + d + '_images'))\n","#     print('d')\n","#   MetadataCatalog.get(d + '_images').set(thing_classes=['no', 'cow', 'cow1'])\n","\n","# DatasetCatalog.register('train_images', get_train_dicts)\n","# MetadataCatalog.get('train_images').set(thing_classes=['no', 'cow', 'cow1'])\n","\n","cow_metadata = MetadataCatalog.get('train_images')\n","print(cow_metadata)"],"metadata":{"id":"EswnC8qi-FOv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset_dicts = get_train_dicts('../train_images')\n","for d in random.sample(dataset_dicts, 3):\n","  img = cv2.imread(d['file_name'])\n","  visualizer = Visualizer(img[:, :, ::-1], metadata = cow_metadata, scale=0.5)\n","  out = visualizer.draw_dataset_dict(d)\n","  cv2_imshow(out.get_image()[:, :, ::-1])"],"metadata":{"id":"CvY9vaTc-G98"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pwd"],"metadata":{"id":"OmCve6fmBwN6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from detectron2.engine import DefaultTrainer\n","\n","cfg = get_cfg()\n","cfg.merge_from_file(model_zoo.get_config_file('COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml'))\n","cfg.DATASETS.TRAIN = ('train_images',)\n","cfg.DATASETS.TEST = ()\n","cfg.DATALOADER.NUM_WORKERS = 2\n","cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url('COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml')\n","cfg.SOLVER.IMS_PER_BATCH = 2\n","cfg.SOLVER.BASE_LR = 0.00025\n","cfg.SOLVER.MAX_ITER = 10\n","cfg.SOLVER.STEPS = []\n","cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n","cfg.MODEL.ROI_HEADS.NUM_CLASSES = 2\n","\n","os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n","trainer = DefaultTrainer(cfg)\n","trainer.resume_or_load(resume=False)\n","trainer.train()"],"metadata":{"id":"KFk9yMYv-LS-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%load_ext tensorboard\n","%tensorboard --logdir output"],"metadata":{"id":"JhhXIRf4E35G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%cd train_images/"],"metadata":{"id":"XYv5ushpseC2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%cd .."],"metadata":{"id":"9LEMyJZI4oyo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pwd"],"metadata":{"id":"Q7m1Epxss6NJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, 'model_final.pth')\n","cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.8\n","predictor = DefaultPredictor(cfg)"],"metadata":{"id":"COu4AS_gE4ZP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from detectron2.utils.visualizer import ColorMode\n","\n","dataset_dicts = get_train_dicts('../train_images')\n","for d in random.sample(dataset_dicts, 5):\n","  img = cv2.imread('../train_images/'+d['file_name'])\n","  print(d['file_name'])\n","  outputs = predictor(img)\n","  visualizer = Visualizer(img[:, :, ::-1], metadata = cow_metadata, scale=0.5, instance_mode = ColorMode.IMAGE_BW)\n","  out = visualizer.draw_instance_predictions(outputs['instances'].to('cpu'))\n","  cv2_imshow(out.get_image()[:, :, ::-1])\n","  print(outputs)"],"metadata":{"id":"-JM57D7PE70H"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# json 파일 출력하는법 + test_image모두 돌리는거\n","### 각 셀마다 실행하기 전에 경로지정 잘해야됨"],"metadata":{"id":"PdkkGfOQn8fk"}},{"cell_type":"code","source":["import skimage\n","from skimage import measure\n","\n","def close_contour(contour):\n","  if not np.array_equal(contour[0], contour[-1]):\n","    contour = np.vstack((contour, contour[0]))\n","  return contour\n","\n","def binary_mask_to_polygon(binary_mask, tolerance=0):\n","  polygons = []\n","  # pad mask to close contours of shapes which start and end at an edge\n","  padded_binary_mask = np.pad(binary_mask, pad_width=1, mode='constant', constant_values=0)\n","  contours = measure.find_contours(padded_binary_mask, 0.5)\n","  contours = np.subtract(contours, 1)\n","  for contour in contours:\n","    contour = close_contour(contour)\n","    contour = measure.approximate_polygon(contour, tolerance)\n","    if len(contour) < 3:\n","      continue\n","    contour = np.flip(contour, axis=1)\n","    segmentation = contour.ravel().tolist()\n","    # after padding and subtracting 1 we may get -0.5 points in our segmentation\n","    segmentation = [0 if i < 0 else i for i in segmentation]\n","    polygons.append(segmentation)\n","  return polygons"],"metadata":{"id":"NNWk7IYFL-td"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pwd #아마 train_images로 되있을꺼임"],"metadata":{"id":"itYtUXF8UOw8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%cd .."],"metadata":{"id":"CjQCk3rlUmDf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pwd"],"metadata":{"id":"CdjGMjFRtR38"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%cd test_images \n","#테스트할 이미지의 test_image_path_list를 만들어주기 위해 test_images폴더로 이동"],"metadata":{"id":"i7CJEOW6Us0Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_dir = '.'\n","\n","test_img_path_list = []\n"," \n","for (root, dirs, files) in os.walk(test_dir):\n","    if len(files) > 0:\n","        for file_name in files:\n","            if os.path.splitext(file_name)[1] in possible_img_extension:\n","                test_img_path = root + '/' + file_name\n","                \n","                # 경로에서 \\를 모두 /로 바꿔줘야함\n","                test_img_path = test_img_path.replace('\\\\', '/') # \\는 \\\\로 나타내야함 \n","                test_img_path = test_img_path[2:]        \n","                test_img_path_list.append(test_img_path)\n","\n","test_img_path_list.sort()\n","\n","#print(test_img_path_list[:2])"],"metadata":{"id":"6VzNdqy5T9xt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pwd #test_imgaes인거 경로 확인 하고 아래 실행해야함"],"metadata":{"id":"LhFa-sAwYcBk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["file_path = \"../test_answer.json\"\n","\n","test_data = {}\n","test_data[\"images\"] = []\n","test_data[\"annotations\"] = []\n","\n","for d in test_img_path_list:\n","  timg = cv2.imread(d)\n","  #cv2_imshow(timg)\n","  h, w, c = timg.shape\n","  test_data[\"images\"].append({\n","      \"file_name\": d,\n","      \"width\": int(w),\n","      \"height\": int(h),\n","      \"id\": int(d[5:9])\n","  })\n","  outputs = predictor(timg)\n","  pred_masks_tensor = outputs['instances'].get_fields()['pred_masks']\n","  pred_classes = outputs['instances'].get_fields()['pred_classes']\n","  classes = pred_classes.cpu().numpy()\n","  mask = pred_masks_tensor.cpu().numpy()\n","  mask_array = outputs[\"instances\"].pred_masks.cpu().numpy()\n","  num_instances = mask_array.shape[0]\n","  for a in range(num_instances):\n","    poly=binary_mask_to_polygon(mask[a])\n","    test_data['annotations'].append({\n","        \"image_id\": int(d[5:9]),\n","        \"segmentation\": poly[0],\n","        \"category_id\": int(classes[a] + 1),\n","        \"conf\": float(0.0)\n","    })\n","\n","\n","with open(file_path, 'w') as outfile:\n","  json.dump(test_data, outfile)"],"metadata":{"id":"LYAEFXueguMj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cd .. #json 출력 확인해보기 - 상위디렉토리 이동"],"metadata":{"id":"p01pBORvmr7w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!cat test_answer.json #json파일 열어보기"],"metadata":{"id":"ra5C5smemuni"},"execution_count":null,"outputs":[]}]}